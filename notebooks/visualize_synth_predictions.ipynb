{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e264e0fa2394921a703c5700a989369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=77, description='z', max=154), Output()), _dom_classes=('widget-interactâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_slice(z)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "input_img_path = \"/home/fp427/rds/rds-cam-segm-7tts6phZ4tw/mission/nnunet/nnUNet_raw/Dataset008_synthseg/imagesTs/synthseg_0000_0001.nii.gz\"\n",
    "segmentation_img_path = \"/home/fp427/rds/rds-cam-segm-7tts6phZ4tw/mission/nnunet/nnUNet_results/Dataset008_synthseg/synthseg_0000.nii.gz\"\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Load the images\n",
    "input_img = nib.load(input_img_path)\n",
    "segmentation_img = nib.load(segmentation_img_path)\n",
    "\n",
    "input_data = input_img.get_fdata()\n",
    "seg_data = segmentation_img.get_fdata().astype(int)\n",
    "\n",
    "# Extract shape (assume shape is something like (X, Y, Z))\n",
    "X, Y, Z = input_data.shape\n",
    "\n",
    "# Define the label mapping (from the given JSON)\n",
    "labels = {\n",
    "    \"background\": 0,\n",
    "    \"left_cerebral_white_matter/right_cerebral_white_matter\": 1,\n",
    "    \"left_cerebral_cortex/right_cerebral_cortex\": 2,\n",
    "    \"left_lateral_ventricle/right_lateral_ventricle\": 3,\n",
    "    \"left_inferior_lateral_ventricle/right_inferior_lateral_ventricle\": 4,\n",
    "    \"left_cerebellum_white_matter/right_cerebellum_white_matter\": 5,\n",
    "    \"left_cerebellum_cortex/right_cerebellum_cortex\": 6,\n",
    "    \"left_thalamus_proper/right_thalamus_proper\": 7,\n",
    "    \"left_caudate/right_caudate\": 8,\n",
    "    \"left_putamen/right_putamen\": 9,\n",
    "    \"left_pallidum/right_pallidum\": 10,\n",
    "    \"left_hippocampus/right_hippocampus\": 11,\n",
    "    \"left_amygdala/right_amygdala\": 12,\n",
    "    \"left_accumbens_area/right_accumbens_area\": 13,\n",
    "    \"left_ventral_dc/right_ventral_dc\": 14,\n",
    "    \"left_vessel/right_vessel\": 15,\n",
    "    \"left_choroid_plexus/right_choroid_plexus\": 16,\n",
    "    \"third_ventricle\": 17,\n",
    "    \"fourth_ventricle\": 18,\n",
    "    \"brain_stem\": 19,\n",
    "    \"csf\": 20,\n",
    "    \"left_undetermined\": 21,\n",
    "    \"fifth_ventricle\": 22,\n",
    "    \"wm_hypointensities\": 23,\n",
    "    \"non_wm_hypointensities\": 24,\n",
    "    \"optic_chiasm\": 25,\n",
    "    \"air_internal\": 26,\n",
    "    \"artery\": 27,\n",
    "    \"eyes\": 28,\n",
    "    \"other_tissues\": 29,\n",
    "    \"rectus_muscles\": 30,\n",
    "    \"mucosa\": 31,\n",
    "    \"skin\": 32,\n",
    "    \"spinal_cord\": 33,\n",
    "    \"vein\": 34,\n",
    "    \"bone_cortical\": 35,\n",
    "    \"bone_cancellous\": 36,\n",
    "    \"cortical_csf\": 37,\n",
    "    \"optic_nerve\": 38\n",
    "}\n",
    "\n",
    "# We have 0-based class indexing from the values. Let's create a colormap.\n",
    "# background = 0 -> black\n",
    "# For the other classes, we can use a range of distinguishable colors.\n",
    "num_classes = max(labels.values()) + 1\n",
    "colors = np.zeros((num_classes, 4))\n",
    "colors[0] = [0, 0, 0, 1]  # black for background\n",
    "\n",
    "# Assign random distinct colors to each class except background\n",
    "# For simplicity, we can just choose a colormap and pick colors from it.\n",
    "# Let's use a tab20 or rainbow for distinct colors.\n",
    "cmap_base = plt.cm.tab20(np.linspace(0,1,num_classes))\n",
    "colors[1:] = cmap_base[1:]  # assign from colormap\n",
    "\n",
    "# Create a ListedColormap\n",
    "seg_cmap = ListedColormap(colors)\n",
    "\n",
    "# Prepare a nice legend for the classes\n",
    "# We'll create a custom legend with colored patches.\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "label_patches = []\n",
    "for k, v in labels.items():\n",
    "    # skip classes not actually present (optional)\n",
    "    # But let's just show all as per given info\n",
    "    color = seg_cmap(v)\n",
    "    patch = mpatches.Patch(color=color, label=f\"{k} ({v})\")\n",
    "    label_patches.append(patch)\n",
    "\n",
    "def plot_slice(z):\n",
    "    # Create figure and subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.suptitle(f\"Slice {z}\", fontsize=16)\n",
    "    \n",
    "    # Left: input image\n",
    "    axes[0].imshow(input_data[:,:,z].T, cmap='gray', origin='lower')\n",
    "    axes[0].set_title(\"Input MRI\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Right: segmentation\n",
    "    axes[1].imshow(seg_data[:,:,z].T, cmap=seg_cmap, origin='lower', interpolation='nearest')\n",
    "    axes[1].set_title(\"Segmentation\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Add the legend outside the plot\n",
    "    # We can place it to the right side of the figure\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    legend_ax = fig.add_axes([0.82, 0.1, 0.15, 0.8]) \n",
    "    legend_ax.axis('off')\n",
    "    legend_ax.legend(handles=label_patches, loc='upper left', fontsize='small', borderaxespad=0.)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Use ipywidget to interactively explore slices\n",
    "interact(plot_slice, z=IntSlider(min=0, max=Z-1, step=1, value=Z//2))\n",
    "\n",
    "\n",
    "gif_output_path = \"/home/fp427/rds/rds-cam-segm-7tts6phZ4tw/mission/gif_outputs\"\n",
    "gif_file_name = \"synaptive_t1_anatomical_segmentation.gif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1d6a8ec85e08>:74: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap_base = plt.cm.get_cmap('hsv', num_classes)\n",
      "<ipython-input-1-1d6a8ec85e08>:118: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images = [imageio.imread(frame) for frame in frames]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import imageio\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Paths\n",
    "input_img_path = \"/home/fp427/rds/rds-cam-segm-7tts6phZ4tw/mission/nnunet/nnUNet_raw/Dataset008_synthseg/imagesTs/synthseg_0000_0001.nii.gz\"\n",
    "segmentation_img_path = \"/home/fp427/rds/rds-cam-segm-7tts6phZ4tw/mission/nnunet/nnUNet_results/Dataset008_synthseg/synthseg_0000.nii.gz\"\n",
    "\n",
    "gif_output_path = \"/home/fp427/rds/rds-cam-segm-7tts6phZ4tw/mission/gif_outputs\"\n",
    "gif_file_name = \"synaptive_t1_anatomical_segmentation.gif\"\n",
    "\n",
    "# Load the images\n",
    "input_img = nib.load(input_img_path)\n",
    "segmentation_img = nib.load(segmentation_img_path)\n",
    "\n",
    "input_data = input_img.get_fdata()\n",
    "seg_data = segmentation_img.get_fdata().astype(int)\n",
    "\n",
    "# Extract shape (assume shape is (X, Y, Z))\n",
    "X, Y, Z = input_data.shape\n",
    "\n",
    "# Define the label mapping (from the given JSON)\n",
    "labels = {\n",
    "    \"background\": 0,\n",
    "    \"left_cerebral_white_matter/right_cerebral_white_matter\": 1,\n",
    "    \"left_cerebral_cortex/right_cerebral_cortex\": 2,\n",
    "    \"left_lateral_ventricle/right_lateral_ventricle\": 3,\n",
    "    \"left_inferior_lateral_ventricle/right_inferior_lateral_ventricle\": 4,\n",
    "    \"left_cerebellum_white_matter/right_cerebellum_white_matter\": 5,\n",
    "    \"left_cerebellum_cortex/right_cerebellum_cortex\": 6,\n",
    "    \"left_thalamus_proper/right_thalamus_proper\": 7,\n",
    "    \"left_caudate/right_caudate\": 8,\n",
    "    \"left_putamen/right_putamen\": 9,\n",
    "    \"left_pallidum/right_pallidum\": 10,\n",
    "    \"left_hippocampus/right_hippocampus\": 11,\n",
    "    \"left_amygdala/right_amygdala\": 12,\n",
    "    \"left_accumbens_area/right_accumbens_area\": 13,\n",
    "    \"left_ventral_dc/right_ventral_dc\": 14,\n",
    "    \"left_vessel/right_vessel\": 15,\n",
    "    \"left_choroid_plexus/right_choroid_plexus\": 16,\n",
    "    \"third_ventricle\": 17,\n",
    "    \"fourth_ventricle\": 18,\n",
    "    \"brain_stem\": 19,\n",
    "    \"csf\": 20,\n",
    "    \"left_undetermined\": 21,\n",
    "    \"fifth_ventricle\": 22,\n",
    "    \"wm_hypointensities\": 23,\n",
    "    \"non_wm_hypointensities\": 24,\n",
    "    \"optic_chiasm\": 25,\n",
    "    \"air_internal\": 26,\n",
    "    \"artery\": 27,\n",
    "    \"eyes\": 28,\n",
    "    \"other_tissues\": 29,\n",
    "    \"rectus_muscles\": 30,\n",
    "    \"mucosa\": 31,\n",
    "    \"skin\": 32,\n",
    "    \"spinal_cord\": 33,\n",
    "    \"vein\": 34,\n",
    "    \"bone_cortical\": 35,\n",
    "    \"bone_cancellous\": 36,\n",
    "    \"cortical_csf\": 37,\n",
    "    \"optic_nerve\": 38\n",
    "}\n",
    "\n",
    "# Create a colormap for segmentation\n",
    "num_classes = max(labels.values()) + 1\n",
    "colors = np.zeros((num_classes, 4))\n",
    "colors[0] = [0, 0, 0, 1]  # black for background\n",
    "\n",
    "cmap_base = plt.cm.get_cmap('hsv', num_classes)\n",
    "colors[1:] = cmap_base(range(1, num_classes))\n",
    "seg_cmap = ListedColormap(colors)\n",
    "\n",
    "# Create legend patches\n",
    "label_patches = []\n",
    "for k, v in labels.items():\n",
    "    color = seg_cmap(v)\n",
    "    patch = mpatches.Patch(color=color, label=f\"{k} ({v})\")\n",
    "    label_patches.append(patch)\n",
    "\n",
    "# Create output directories if not existing\n",
    "os.makedirs(gif_output_path, exist_ok=True)\n",
    "temp_dir = os.path.join(gif_output_path, \"temp_frames\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "frames = []\n",
    "for z_idx in range(Z):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    fig.suptitle(f\"Slice {z_idx}\", fontsize=16)\n",
    "    \n",
    "    # Left: Input MRI\n",
    "    axes[0].imshow(input_data[:,:,z_idx].T, cmap='gray', origin='lower')\n",
    "    axes[0].set_title(\"Input MRI\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Right: Segmentation\n",
    "    axes[1].imshow(seg_data[:,:,z_idx].T, cmap=seg_cmap, origin='lower', interpolation='nearest')\n",
    "    axes[1].set_title(\"Segmentation\")\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Add legend\n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    legend_ax = fig.add_axes([0.82, 0.1, 0.15, 0.8])\n",
    "    legend_ax.axis('off')\n",
    "    legend_ax.legend(handles=label_patches, loc='upper left', fontsize='small', borderaxespad=0.)\n",
    "    \n",
    "    # Save the frame\n",
    "    frame_path = os.path.join(temp_dir, f\"frame_{z_idx:03d}.png\")\n",
    "    plt.savefig(frame_path, dpi=72)\n",
    "    plt.close(fig)\n",
    "    frames.append(frame_path)\n",
    "\n",
    "# Create a GIF from the saved frames\n",
    "images = [imageio.imread(frame) for frame in frames]\n",
    "imageio.mimsave(os.path.join(gif_output_path, gif_file_name), images, fps=5)  # Adjust fps as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
